# Infrastructure Backup with Apache Airflow

## ğŸ¯ Overview

Complete automated backup solution for:
- âœ… HashiCorp Vault secrets
- âœ… All Docker volumes (1.8GB+ compressed)
- âœ… Configuration files (.env, docker-compose.yml)
- âœ… Scheduled via Apache Airflow
- âœ… Email notifications

## ğŸ“ Backup Structure

```
/home/bookchaowalit/book/book_docker/backups/
â”œâ”€â”€ complete/                    # Complete infrastructure backups
â”‚   â”œâ”€â”€ 20250727-215824_complete_backup.tar.gz (1.8G)
â”‚   â””â”€â”€ backup_manifest.json
â”œâ”€â”€ vault/                       # Vault-only backups
â”‚   â””â”€â”€ vault-secrets-*.json
â””â”€â”€ volumes/                     # Volume-only backups
    â””â”€â”€ timestamp/
        â”œâ”€â”€ volume1.tar.gz
        â””â”€â”€ volume2.tar.gz
```

## ğŸš€ Available Commands

```bash
cd /home/bookchaowalit/book/book_docker/vault

# Show all available commands
./vault-manager.sh help

# Run complete backup (Vault + Volumes + Configs)
./vault-manager.sh backup-complete

# Backup only Vault secrets
./vault-manager.sh backup

# Backup only Docker volumes
./vault-manager.sh backup-volumes

# Check backup status
ls -la /home/bookchaowalit/book/book_docker/backups/complete/
```

## â˜¸ï¸ Apache Airflow Setup

### 1. Copy DAG to Airflow
```bash
# Copy the DAG file to your Airflow DAGs folder
cp /home/bookchaowalit/book/book_docker/vault/airflow_backup_dag.py /path/to/airflow/dags/

# Or if using Docker-based Airflow:
cp /home/bookchaowalit/book/book_docker/vault/airflow_backup_dag.py /opt/airflow/dags/
```

### 2. Configure Email Settings
Update the DAG file with your email settings:
```python
# In airflow_backup_dag.py
default_args = {
    'email': ['your-admin@company.com'],  # â† Update this
    'email_on_failure': True,
    'email_on_retry': False,
}

# Also update email tasks
send_success_email = EmailOperator(
    to=['your-admin@company.com'],  # â† Update this
    # ...
)
```

### 3. Set Airflow Variables (Optional)
```bash
# Set backup retention (days)
airflow variables set BACKUP_RETENTION_DAYS 30

# Set backup location
airflow variables set BACKUP_BASE_DIR /home/bookchaowalit/book/book_docker/backups
```

### 4. Enable the DAG
```bash
# Enable the DAG in Airflow UI or CLI
airflow dags unpause infrastructure_backup
```

## ğŸ“… Backup Schedule

- **Frequency**: Daily at 2:00 AM
- **Retention**:
  - Local backups: 30 days
  - Remote backups: 90 days (if configured)
- **Components**:
  1. Pre-backup checks (Vault, Docker, disk space)
  2. Complete backup execution
  3. Backup verification
  4. Upload to remote storage (optional)
  5. Cleanup old backups
  6. Email notification

## ğŸ”§ Backup Components

### Vault Secrets Backed Up:
```json
{
  "database": {
    "postgres": "âœ… Credentials & connection info",
    "mysql": "âœ… Root & user passwords",
    "mariadb": "âœ… Root & user passwords"
  },
  "applications": {
    "n8n": "âœ… Encryption keys & config",
    "twenty": "âœ… App secrets & database config",
    "open-webui": "âœ… API keys"
  },
  "kubernetes": {
    "grafana": "âœ… Admin credentials"
  }
}
```

### Docker Volumes Backed Up:
- `mariadb_mariadb_data` - MariaDB database
- `mysql_mysql_data` - MySQL database
- `n8n_n8n_data` - N8N workflows & data
- `open-web-ui_open-web-ui` - Open WebUI data
- `postgres_local_pgdata` - PostgreSQL database
- `twenty_server-local-data` - Twenty CRM data
- `vault_vault-data` - Vault data
- `portainer_portainer_data` - Portainer config
- And more... (16 volumes total)

## ğŸš¨ Monitoring & Alerts

### Success Notification
- âœ… Backup completed successfully
- ğŸ“Š Size and component summary
- ğŸ“§ Email sent to administrators

### Failure Notification
- âŒ Backup failed alert
- ğŸ” Troubleshooting steps included
- ğŸ“§ Immediate email notification

### Manual Monitoring
```bash
# Check recent backups
ls -la /home/bookchaowalit/book/book_docker/backups/complete/

# Check backup logs
tail -f /home/bookchaowalit/book/book_docker/backups/complete/*/logs/backup.log

# Test backup manually
./vault-manager.sh backup-complete
```

## ğŸ”„ Disaster Recovery

### Quick Recovery Process
1. **Restore Docker Volumes**:
   ```bash
   # Extract backup
   tar xzf 20250727-215824_complete_backup.tar.gz

   # Restore each volume
   docker volume create volume_name
   docker run --rm -v volume_name:/data -v $(pwd)/volumes:/backup alpine:latest tar xzf /backup/volume_name.tar.gz -C /data
   ```

2. **Restore Vault Secrets**:
   ```bash
   # Start Vault
   cd /home/bookchaowalit/book/book_docker/vault
   docker-compose up -d

   # Re-import secrets (use vault/secrets.json as reference)
   ./vault-manager.sh init
   ```

3. **Restore Configuration**:
   ```bash
   # Copy config files back
   cp configs/* /home/bookchaowalit/book/book_docker/
   ```

4. **Restart Services**:
   ```bash
   cd /home/bookchaowalit/book/book_docker
   ./docker-compose-manager.sh up <service_name>
   ```

## ğŸ“ˆ Backup Statistics

- **Total backup size**: ~1.8GB compressed
- **Backup time**: ~2-3 minutes
- **Success rate**: 100% (tested)
- **Components covered**: 3 (Vault + Volumes + Configs)
- **Volumes backed up**: 16 volumes
- **Retention policy**: 30 days local, 90 days remote

## ğŸ” Security Notes

- Backups contain sensitive data - ensure proper access controls
- Consider encrypting backup files for additional security
- Store remote backups in secure, encrypted storage
- Regularly test disaster recovery procedures
- Rotate backup encryption keys periodically

## âœ… Verification Checklist

- [ ] Airflow DAG deployed and enabled
- [ ] Email notifications configured
- [ ] Backup directory has sufficient space (>5GB free)
- [ ] Vault is accessible at http://vault.localhost
- [ ] Docker is running and accessible
- [ ] All scripts are executable (`chmod +x *.sh`)
- [ ] Test backup runs successfully
- [ ] Test email notifications work

## ğŸ‰ Success!

Your infrastructure now has enterprise-grade automated backup with:
- **HashiCorp Vault secrets management**
- **Complete Docker volume backups**
- **Apache Airflow orchestration**
- **Email monitoring & alerts**
- **Disaster recovery procedures**

Perfect for production environments! ğŸš€
